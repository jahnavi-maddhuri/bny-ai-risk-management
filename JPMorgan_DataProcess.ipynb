{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc28af4c-9dca-40f2-82a9-c8eebb29c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "# !pip install feedparser pyarrow requests\n",
    "\n",
    "# necessary inputs\n",
    "import json, os, csv\n",
    "from datetime import timezone\n",
    "import requests\n",
    "import feedparser\n",
    "from dateutil import parser as dtparse\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time, random, re\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4843586a-9a82-4cff-916d-0828aa020929",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEED_URL = \"https://jpmorganchaseco.gcs-web.com/rss/news-releases.xml\"\n",
    "\n",
    "OUT_CSV = \"data/jpm_press_releases.csv\"\n",
    "STATE_JSON = \"data/jpm_rss_state.json\"\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\"User-Agent\": \"BNYCapstone/1.0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7d4e1ef-b788-49c0-b9da-4751f038cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_feed_bytes(url: str) -> bytes:\n",
    "    r = SESSION.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "def to_iso_utc(dt_str: str | None) -> str:\n",
    "    if not dt_str:\n",
    "        return \"\"\n",
    "    try:\n",
    "        dt = dtparse.parse(dt_str)\n",
    "        if not dt.tzinfo:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return dt.astimezone(timezone.utc).isoformat()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def parse_feed_to_df(feed_bytes: bytes, source_name: str = \"JPMorganChase\") -> pd.DataFrame:\n",
    "    parsed = feedparser.parse(feed_bytes)\n",
    "    rows = []\n",
    "    for e in parsed.entries:\n",
    "        guid = (e.get(\"id\") or e.get(\"guid\") or e.get(\"link\") or\n",
    "                f\"{e.get('title','')}-{e.get('published','')}\")\n",
    "        title = (e.get(\"title\") or \"\").strip()\n",
    "        link = (e.get(\"link\") or \"\").strip()\n",
    "        published = to_iso_utc(e.get(\"published\") or e.get(\"updated\"))\n",
    "\n",
    "        tags = []\n",
    "        if isinstance(e.get(\"tags\"), list):\n",
    "            for t in e[\"tags\"]:\n",
    "                label = t.get(\"term\") or t.get(\"label\")\n",
    "                if label:\n",
    "                    tags.append(str(label).strip())\n",
    "        categories = \"; \".join(tags)\n",
    "        summary = (e.get(\"summary\") or e.get(\"description\") or \"\").strip()\n",
    "        summary = \" \".join(summary.split())\n",
    "        rows.append({\n",
    "            \"source\": source_name,\n",
    "            \"guid\": guid.strip(),\n",
    "            \"title\": title,\n",
    "            \"link\": link,\n",
    "            \"published_utc\": published,\n",
    "            \"summary\": summary\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def load_seen(state_path: str = STATE_JSON) -> set[str]:\n",
    "    if not os.path.exists(state_path):\n",
    "        return set()\n",
    "    try:\n",
    "        with open(state_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return set(data.get(\"seen_ids\", []))\n",
    "    except Exception:\n",
    "        return set()\n",
    "\n",
    "def save_seen(seen: set[str], state_path: str = STATE_JSON) -> None:\n",
    "    with open(state_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"seen_ids\": sorted(seen)}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63d8fda-8dcd-4626-96d3-c194625221f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows added to csv file in: data/jpm_press_releases.csv\n",
      "10 guids added to metadata file in: data/jpm_rss_state.json\n"
     ]
    }
   ],
   "source": [
    "# MAIN SCRIPT\n",
    "\n",
    "# fetch data\n",
    "feed_bytes = fetch_feed_bytes(FEED_URL)\n",
    "df = parse_feed_to_df(feed_bytes)\n",
    "\n",
    "# filter for new data\n",
    "seen = load_seen(STATE_JSON)\n",
    "is_new = ~df[\"guid\"].isin(seen)\n",
    "df_new = df[is_new].copy()\n",
    "\n",
    "# find accurate summaries\n",
    "genai.configure(api_key=\"AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8\")\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "df_new[\"summary\"] = df_new[\"link\"].apply(\n",
    "    lambda x: model.generate_content(f\"For the article in this link, {x}, \\\n",
    "    provide me a summary of the article. 2-3 sentences.\").text\n",
    ")\n",
    "\n",
    "# store feed data in csv\n",
    "df_new.to_csv(OUT_CSV, mode=\"a\", header=False, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "print(f'{df_new.shape[0]} rows added to csv file in: {OUT_CSV}')\n",
    "\n",
    "# update json state (metadata)\n",
    "seen.update(df_new[\"guid\"].tolist())\n",
    "save_seen(seen, STATE_JSON)\n",
    "print(f'{len(seen)} guids in to metadata file in: {STATE_JSON}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c37d9-f42d-4fd3-941d-df6978d70780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
