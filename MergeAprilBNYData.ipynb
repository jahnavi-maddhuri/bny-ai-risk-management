{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "23c3c4f4-2f1f-4e12-9e97-4343805618d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, math\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8\")\n",
    "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = (\n",
    "    \"You will receive a list of items, each with an 'id' and a 'url'. \"\n",
    "    \"For each url, write a concise 2-3 sentence summary of the article at that link. \"\n",
    "    \"Return ONLY a JSON array where each element is an object with keys: \"\n",
    "    \"id (copied from input) and summary (a string). \"\n",
    "    \"Do not include any other keys. Do not include any text outside the JSON. \"\n",
    "    \"Do not include comments, markdown, or explanations.\"\n",
    "    \"If the link is not found or if unable to summarize, only output: <no summary found> for that url.\"\n",
    ")\n",
    "\n",
    "def build_prompt(batch_items: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Build a single prompt with up to 40 items.\n",
    "    We serialize the input as JSON so the model can return parallel JSON.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        SYSTEM_INSTRUCTIONS\n",
    "        + \"\\n\\nINPUT_JSON:\\n\"\n",
    "        + json.dumps(batch_items, ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "def call_gemini_json(prompt: str, max_retries: int = 3, base_sleep: float = 8.0):\n",
    "    \"\"\"\n",
    "    Call Gemini and parse strict JSON. Retries on quota errors (429) with backoff.\n",
    "    Returns a Python object parsed from the model's JSON text.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = model.generate_content(prompt)\n",
    "            text = resp.text or \"\"\n",
    "            # Try to extract JSON directly\n",
    "            return json.loads(text)\n",
    "        except json.JSONDecodeError:\n",
    "            # If the model wrapped JSON in code fences or added text, try to salvage\n",
    "            stripped = text.strip()\n",
    "            # crude fence removal if present\n",
    "            if stripped.startswith(\"```\"):\n",
    "                stripped = stripped.strip(\"`\")\n",
    "                # remove leading language hints like json\n",
    "                if \"\\n\" in stripped:\n",
    "                    stripped = stripped.split(\"\\n\", 1)[1]\n",
    "            try:\n",
    "                return json.loads(stripped)\n",
    "            except Exception:\n",
    "                if attempt == max_retries:\n",
    "                    raise\n",
    "        except Exception as e:\n",
    "            # Simple detection of quota/429; fall back to fixed backoff\n",
    "            # Many Gemini quota errors surface as RESOURCE_EXHAUSTED with suggested retry.\n",
    "            sleep_s = base_sleep * attempt\n",
    "            time.sleep(sleep_s)\n",
    "            if attempt == max_retries:\n",
    "                raise\n",
    "\n",
    "# def summarize_links_in_batches(\n",
    "#     df,\n",
    "#     link_col: str = \"link\",\n",
    "#     out_col: str = \"summary\",\n",
    "#     batch_size: int = 40,\n",
    "#     max_calls: int = 10,\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Summarize links in df[link_col] using Gemini in batches of <= batch_size.\n",
    "#     Writes results to df[out_col]. Makes at most max_calls API calls.\n",
    "#     Partially fills df[out_col] even if later calls fail.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if out_col not in df.columns:\n",
    "#         df[out_col] = None\n",
    "\n",
    "#     # Select rows that still need summaries\n",
    "#     todo_idx = df.index[df[out_col].isna() | (df[out_col] == \"\")].tolist()\n",
    "#     if not todo_idx:\n",
    "#         return  # nothing to do\n",
    "\n",
    "#     # Cap total items by batch_size * max_calls\n",
    "#     max_items = batch_size * max_calls\n",
    "#     todo_idx = todo_idx[:max_items]\n",
    "\n",
    "#     # Create batches\n",
    "#     batches = [\n",
    "#         todo_idx[i : i + batch_size] for i in range(0, len(todo_idx), batch_size)\n",
    "#     ]\n",
    "\n",
    "#     calls_made = 0\n",
    "#     for batch_indices in batches:\n",
    "#         if calls_made >= max_calls:\n",
    "#             break\n",
    "\n",
    "#         batch_items = [{\"id\": int(i), \"url\": str(df.at[i, link_col])} for i in batch_indices]\n",
    "#         prompt = build_prompt(batch_items)\n",
    "\n",
    "#         try:\n",
    "#             result = call_gemini_json(prompt)\n",
    "#         except Exception as e:\n",
    "#             # Keep partial progress, then stop further calls (stay within max_calls intent)\n",
    "#             # You could log/print e here if desired.\n",
    "#             break\n",
    "\n",
    "#         # Validate and write back\n",
    "#         # Expecting: [{\"id\": <df_index>, \"summary\": \"...\"} ...]\n",
    "#         if isinstance(result, list):\n",
    "#             for obj in result:\n",
    "#                 try:\n",
    "#                     row_id = obj[\"id\"]\n",
    "#                     summary = obj[\"summary\"]\n",
    "#                     if row_id in df.index:\n",
    "#                         df.at[row_id, out_col] = summary\n",
    "#                 except Exception:\n",
    "#                     # Skip malformed objects; continue with others\n",
    "#                     continue\n",
    "\n",
    "#         calls_made += 1\n",
    "\n",
    "#         # Optional throttle to respect 10 RPM even if something else calls us rapidly.\n",
    "#         # With max_calls=10 this caps at ~1 minute total if you keep it enabled.\n",
    "#         # time.sleep(6)\n",
    "\n",
    "#     # Done. df[out_col] now contains summaries for processed rows.\n",
    "#     # Unprocessed rows remain None/\"\" and can be handled in a later run.\n",
    "\n",
    "# # ---------------------------\n",
    "# # Example usage\n",
    "# # ---------------------------\n",
    "# # summarize_links_in_batches(df, link_col=\"link\", out_col=\"summary\",\n",
    "# #                            batch_size=40, max_calls=10)\n",
    "# # df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ec90049f-eccb-498e-b904-e5c5f4098ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/gnews/2024-03-11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1656a41",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission denied: Consumer 'api_key:AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8' has been suspended. [reason: \"CONSUMER_SUSPENDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/346539474943\"\n}\nmetadata {\n  key: \"containerInfo\"\n  value: \"api_key:AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8\"\n}\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"Permission denied: Consumer \\'api_key:AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8\\' has been suspended.\"\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_items \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(i), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m])} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_1]\n\u001b[1;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m build_prompt(batch_items)\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m call_gemini_json(prompt)\n",
      "Cell \u001b[0;32mIn[111], line 37\u001b[0m, in \u001b[0;36mcall_gemini_json\u001b[0;34m(prompt, max_retries, base_sleep)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m         resp \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\n\u001b[1;32m     38\u001b[0m         text \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# Try to extract JSON directly\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    332\u001b[0m             request,\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    836\u001b[0m     request,\n\u001b[1;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    840\u001b[0m )\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    295\u001b[0m     target,\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    297\u001b[0m     sleep_generator,\n\u001b[1;32m    298\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    299\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    300\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m _retry_error_helper(\n\u001b[1;32m    157\u001b[0m         exc,\n\u001b[1;32m    158\u001b[0m         deadline,\n\u001b[1;32m    159\u001b[0m         sleep_iter,\n\u001b[1;32m    160\u001b[0m         error_list,\n\u001b[1;32m    161\u001b[0m         predicate,\n\u001b[1;32m    162\u001b[0m         on_error,\n\u001b[1;32m    163\u001b[0m         exception_factory,\n\u001b[1;32m    164\u001b[0m         timeout,\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    210\u001b[0m         error_list,\n\u001b[1;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    212\u001b[0m         original_timeout,\n\u001b[1;32m    213\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:77\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission denied: Consumer 'api_key:AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8' has been suspended. [reason: \"CONSUMER_SUSPENDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/346539474943\"\n}\nmetadata {\n  key: \"containerInfo\"\n  value: \"api_key:AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8\"\n}\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"Permission denied: Consumer \\'api_key:AIzaSyAm-pqLVce_uYDyOHvJn-wHFaSHp2j3jt8\\' has been suspended.\"\n]"
     ]
    }
   ],
   "source": [
    "batch_1 = [i for i in range(20)]\n",
    "\n",
    "batch_items = [{\"id\": int(i), \"url\": str(df.at[i, 'link'])} for i in batch_1]\n",
    "prompt = build_prompt(batch_items)\n",
    "result = call_gemini_json(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "# Get your free API token from https://huggingface.co/settings/tokens\n",
    "HF_API_TOKEN = \"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\"\n",
    "\n",
    "def get_article_text(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text[:1024]  # Limit to first 1024 chars for summarization\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def summarize_text(text):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_API_TOKEN}\"}\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": text})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]['summary_text']\n",
    "    return None\n",
    "\n",
    "# Apply to dataframe\n",
    "summaries = []\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"Processing {idx+1}/{len(df)}\")\n",
    "    text = get_article_text(row['link'])\n",
    "    if text:\n",
    "        summary = summarize_text(text)\n",
    "        summaries.append(summary)\n",
    "        time.sleep(1)  # Rate limiting\n",
    "    else:\n",
    "        summaries.append(None)\n",
    "\n",
    "df['summary'] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3da1826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>query</th>\n",
       "      <th>target_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>fetched_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b82073738c5fdc75f9a22e73a7ed80d5d4c6d7d91edbd1...</td>\n",
       "      <td>Behind the Alaska Blowout: a Manufacturing Hab...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitwNBV...</td>\n",
       "      <td>Mon, 11 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>BA</td>\n",
       "      <td>2026-01-19T17:19:49.348784-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395eef02e2bbaac1c1ed0d517cd76450210511a758c954...</td>\n",
       "      <td>Airlines Are Cutting Flight Schedules as Boein...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiwgNBV...</td>\n",
       "      <td>Tue, 12 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>BA</td>\n",
       "      <td>2026-01-19T17:19:49.348784-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51b35e461cb11df1cc9b26d513565756307a5adad4e04f...</td>\n",
       "      <td>What's going on with Boeing planes? Safety con...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMie0FVX...</td>\n",
       "      <td>Tue, 12 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>Mashable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>BA</td>\n",
       "      <td>2026-01-19T17:19:49.348784-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76a929bedf09b6a7994203e9f56be29d011cf338bdcb77...</td>\n",
       "      <td>Join the Mobilization Against Boeing’s Defense...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMixAFBV...</td>\n",
       "      <td>Mon, 11 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>The Stranger: Seattle's Only Newspaper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>BA</td>\n",
       "      <td>2026-01-19T17:19:49.348784-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4998c4ae593fea127d604b5d90a3c772cca9fd2fe5e5b0...</td>\n",
       "      <td>The Boeing 747 Cockpit: How It Has Changed Ove...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiigFBV...</td>\n",
       "      <td>Mon, 11 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>Simple Flying</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>BA</td>\n",
       "      <td>2026-01-19T17:19:49.348784-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>4c430c847eebc744333e62778362ced5c85bebf110a730...</td>\n",
       "      <td>Man Claims Tesla Autopilot Possibly Saved His ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMigAFBV...</td>\n",
       "      <td>Mon, 11 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>TeslaNorth.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2026-01-19T17:33:08.897280-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2c54434f1e875972d7799b8da031c901b91ba95ee3f97f...</td>\n",
       "      <td>Southeast Asia becomes Tesla's priority for ex...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimAFBV...</td>\n",
       "      <td>Tue, 12 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>Vietnam+ (VietnamPlus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2026-01-19T17:33:08.897280-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>85022243ea5730c5853a4dfb99939156d1db6d43efdff2...</td>\n",
       "      <td>Report: Angela Chao may have died after accide...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi1wFBV...</td>\n",
       "      <td>Mon, 11 Mar 2024 15:50:21 GMT</td>\n",
       "      <td>WFTV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2026-01-19T17:33:08.897280-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>8eb85cdc156e7c02827e3af05586f2b61367508a8ca199...</td>\n",
       "      <td>Tesla’s “Bulletproof,” “Stainless,” “Indestruc...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMigwFBV...</td>\n",
       "      <td>Tue, 12 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>Slate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2026-01-19T17:33:08.897280-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>93ce4431fc5454b6af99dd21dd901ebb96cd6a1240652c...</td>\n",
       "      <td>Caviar Unveils Samsung Galaxy S24 Ultra Cybert...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMigwFBV...</td>\n",
       "      <td>Tue, 12 Mar 2024 07:00:00 GMT</td>\n",
       "      <td>TechEBlog -</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2026-01-19T17:33:08.897280-05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  \\\n",
       "0    b82073738c5fdc75f9a22e73a7ed80d5d4c6d7d91edbd1...   \n",
       "1    395eef02e2bbaac1c1ed0d517cd76450210511a758c954...   \n",
       "2    51b35e461cb11df1cc9b26d513565756307a5adad4e04f...   \n",
       "3    76a929bedf09b6a7994203e9f56be29d011cf338bdcb77...   \n",
       "4    4998c4ae593fea127d604b5d90a3c772cca9fd2fe5e5b0...   \n",
       "..                                                 ...   \n",
       "456  4c430c847eebc744333e62778362ced5c85bebf110a730...   \n",
       "457  2c54434f1e875972d7799b8da031c901b91ba95ee3f97f...   \n",
       "458  85022243ea5730c5853a4dfb99939156d1db6d43efdff2...   \n",
       "459  8eb85cdc156e7c02827e3af05586f2b61367508a8ca199...   \n",
       "460  93ce4431fc5454b6af99dd21dd901ebb96cd6a1240652c...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Behind the Alaska Blowout: a Manufacturing Hab...   \n",
       "1    Airlines Are Cutting Flight Schedules as Boein...   \n",
       "2    What's going on with Boeing planes? Safety con...   \n",
       "3    Join the Mobilization Against Boeing’s Defense...   \n",
       "4    The Boeing 747 Cockpit: How It Has Changed Ove...   \n",
       "..                                                 ...   \n",
       "456  Man Claims Tesla Autopilot Possibly Saved His ...   \n",
       "457  Southeast Asia becomes Tesla's priority for ex...   \n",
       "458  Report: Angela Chao may have died after accide...   \n",
       "459  Tesla’s “Bulletproof,” “Stainless,” “Indestruc...   \n",
       "460  Caviar Unveils Samsung Galaxy S24 Ultra Cybert...   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://news.google.com/rss/articles/CBMitwNBV...   \n",
       "1    https://news.google.com/rss/articles/CBMiwgNBV...   \n",
       "2    https://news.google.com/rss/articles/CBMie0FVX...   \n",
       "3    https://news.google.com/rss/articles/CBMixAFBV...   \n",
       "4    https://news.google.com/rss/articles/CBMiigFBV...   \n",
       "..                                                 ...   \n",
       "456  https://news.google.com/rss/articles/CBMigAFBV...   \n",
       "457  https://news.google.com/rss/articles/CBMimAFBV...   \n",
       "458  https://news.google.com/rss/articles/CBMi1wFBV...   \n",
       "459  https://news.google.com/rss/articles/CBMigwFBV...   \n",
       "460  https://news.google.com/rss/articles/CBMigwFBV...   \n",
       "\n",
       "                         published                                  source  \\\n",
       "0    Mon, 11 Mar 2024 07:00:00 GMT                 The Wall Street Journal   \n",
       "1    Tue, 12 Mar 2024 07:00:00 GMT                 The Wall Street Journal   \n",
       "2    Tue, 12 Mar 2024 07:00:00 GMT                                Mashable   \n",
       "3    Mon, 11 Mar 2024 07:00:00 GMT  The Stranger: Seattle's Only Newspaper   \n",
       "4    Mon, 11 Mar 2024 07:00:00 GMT                           Simple Flying   \n",
       "..                             ...                                     ...   \n",
       "456  Mon, 11 Mar 2024 07:00:00 GMT                          TeslaNorth.com   \n",
       "457  Tue, 12 Mar 2024 07:00:00 GMT                  Vietnam+ (VietnamPlus)   \n",
       "458  Mon, 11 Mar 2024 15:50:21 GMT                                    WFTV   \n",
       "459  Tue, 12 Mar 2024 07:00:00 GMT                                   Slate   \n",
       "460  Tue, 12 Mar 2024 07:00:00 GMT                             TechEBlog -   \n",
       "\n",
       "     summary                                              query target_date  \\\n",
       "0        NaN  (\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...  2024-03-11   \n",
       "1        NaN  (\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...  2024-03-11   \n",
       "2        NaN  (\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...  2024-03-11   \n",
       "3        NaN  (\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...  2024-03-11   \n",
       "4        NaN  (\"Boeing\" OR \"BA\") -gossip -celebrity -\"fantas...  2024-03-11   \n",
       "..       ...                                                ...         ...   \n",
       "456      NaN  (\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...  2024-03-11   \n",
       "457      NaN  (\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...  2024-03-11   \n",
       "458      NaN  (\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...  2024-03-11   \n",
       "459      NaN  (\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...  2024-03-11   \n",
       "460      NaN  (\"Tesla\" OR \"TSLA\") -gossip -celebrity -\"fanta...  2024-03-11   \n",
       "\n",
       "    ticker                        fetched_at  \n",
       "0       BA  2026-01-19T17:19:49.348784-05:00  \n",
       "1       BA  2026-01-19T17:19:49.348784-05:00  \n",
       "2       BA  2026-01-19T17:19:49.348784-05:00  \n",
       "3       BA  2026-01-19T17:19:49.348784-05:00  \n",
       "4       BA  2026-01-19T17:19:49.348784-05:00  \n",
       "..     ...                               ...  \n",
       "456   TSLA  2026-01-19T17:33:08.897280-05:00  \n",
       "457   TSLA  2026-01-19T17:33:08.897280-05:00  \n",
       "458   TSLA  2026-01-19T17:33:08.897280-05:00  \n",
       "459   TSLA  2026-01-19T17:33:08.897280-05:00  \n",
       "460   TSLA  2026-01-19T17:33:08.897280-05:00  \n",
       "\n",
       "[461 rows x 10 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "831543c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "# Get your free API token from https://huggingface.co/settings/tokens\n",
    "HF_API_TOKEN = \"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\"\n",
    "\n",
    "# def get_article_text(url):\n",
    "#     try:\n",
    "#         article = Article(url)\n",
    "#         article.download()\n",
    "#         article.parse()\n",
    "#         return article.text[:1024]  # Limit to first 1024 chars for summarization\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "# def summarize_text(text):\n",
    "#     API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "#     headers = {\"Authorization\": f\"Bearer {HF_API_TOKEN}\"}\n",
    "    \n",
    "#     response = requests.post(API_URL, headers=headers, json={\"inputs\": text})\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()[0]['summary_text']\n",
    "#     return None\n",
    "\n",
    "# # Apply to dataframe\n",
    "# summaries = []\n",
    "# for idx, row in df.iterrows():\n",
    "#     print(f\"Processing {idx+1}/{len(df)}\")\n",
    "#     text = get_article_text(row['link'])\n",
    "#     if text:\n",
    "#         summary = summarize_text(text)\n",
    "#         summaries.append(summary)\n",
    "#         time.sleep(1)  # Rate limiting\n",
    "#     else:\n",
    "#         summaries.append(None)\n",
    "\n",
    "# df['summary'] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2f9c0dac-e9a0-48cb-8882-0431f67831bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_links_in_batches(\n",
    "    df,\n",
    "    link_col: str = \"link\",\n",
    "    out_col: str = \"summary\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Summarize links from a DataFrame.\n",
    "    Uses the existing batching/JSON architecture (build_prompt + call_gemini_json).\n",
    "    Writes results to df[out_col].\n",
    "    \"\"\"\n",
    "    df\n",
    "    # Ensure output column exists\n",
    "    batches = [[i for i in range(40*x,40*x +40)] for x in range(10)]\n",
    "    print(f'Summaries will be in {len(batches)} batches.')\n",
    "    \n",
    "    calls_made = 0\n",
    "    results = []\n",
    "    for batch_indices in batches:\n",
    "        batch_items = [{\"id\": int(i), \"url\": str(df.at[i, link_col])} for i in batch_indices]\n",
    "        prompt = build_prompt(batch_items)\n",
    "\n",
    "        try:\n",
    "            result = call_gemini_json(prompt)\n",
    "        except Exception:\n",
    "            # Keep partial progress; stop further calls\n",
    "            break\n",
    "\n",
    "        # Expecting: [{\"id\": <df_index>, \"summary\": \"...\"} ...]\n",
    "        # if isinstance(result, list):\n",
    "        #     for obj in result:\n",
    "        #         try:\n",
    "        #             row_id = obj[\"id\"]\n",
    "        #             summary = obj[\"summary\"]\n",
    "        #             if row_id in target_idx:\n",
    "        #                 df.at[row_id, out_col] = summary\n",
    "        #         except Exception:\n",
    "        #             continue\n",
    "        results.append(result)\n",
    "        \n",
    "        calls_made += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "956982d2-ea9d-4235-bbe7-96186ea553b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries will be in 10 batches.\n"
     ]
    }
   ],
   "source": [
    "results = summarize_links_in_batches(df[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8b2957ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c883f",
   "metadata": {},
   "source": [
    "# Try extract text + HF summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a73cf888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/gnews/2025-04-02.csv')\n",
    "# url2 = df.loc[0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "34073220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/22/2026 12:38:01 PM - discarding data: None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m downloaded \u001b[38;5;241m=\u001b[39m trafilatura\u001b[38;5;241m.\u001b[39mfetch_url(url2) \u001b[38;5;66;03m#url works!\u001b[39;00m\n\u001b[1;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m trafilatura\u001b[38;5;241m.\u001b[39mextract(downloaded)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(text[:\u001b[38;5;241m1024\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import trafilatura\n",
    "\n",
    "url = 'https://mashable.com/article/boeing-planes-safety-controversy-explained'\n",
    "url2 = 'https://news.google.com/rss/articles/CBMie0FVX3lxTE45Nk13SnZ5NldKV1ZWN25wZ3dBclFhSm9id09hTVJ4SGZQSlRPdjlvUEhCZE90VGdoLWU4NlMwaWtibDE0Z2g4STNBdjZxVFBsdEhaUWM3RWI4Tko4NG9LQk93VlYxcDJSTHgzMXcwZkJHaUxRWTI4NDc4OA?oc=5&hl=en-US&gl=US&ceid=US:en'\n",
    "downloaded = trafilatura.fetch_url(url2) #url works!\n",
    "text = trafilatura.extract(downloaded)\n",
    "print(text[:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "08f136b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def get_real_url_selenium(google_url):\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    try:\n",
    "        driver.get(google_url)\n",
    "        time.sleep(2)  # Wait for redirect\n",
    "        actual_url = driver.current_url\n",
    "        driver.quit()\n",
    "        return actual_url\n",
    "    except:\n",
    "        driver.quit()\n",
    "        return google_url\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f3f8f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# get_real_url_selenium(df.loc[2]['link']) # this worked!!\n",
    "df['actual_link'] = df['link'].apply(get_real_url_selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1d025e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>query</th>\n",
       "      <th>target_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>fetched_at</th>\n",
       "      <th>actual_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0628ebdbee231311b2356627bc476f92190cfa22bae7d...</td>\n",
       "      <td>BNY launches new blockchain accounting tool wi...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMipgFBV...</td>\n",
       "      <td>Thu, 03 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>Fortune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://fortune.com/crypto/2025/04/03/bank-new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67e756c3478f59ad1ce1a58e5dd84d20b443ebbf5f58ac...</td>\n",
       "      <td>“A classical guitar for the modern era”: Harle...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMihgFBV...</td>\n",
       "      <td>Thu, 03 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>MusicRadar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://www.musicradar.com/guitars/harley-bent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9698e4b440d2804dacb73299a644a2f24e2efd5f5c094b...</td>\n",
       "      <td>How BK Shivani Found Her Path: A Story of Love...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi7AFBV...</td>\n",
       "      <td>Wed, 02 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>Times of India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://timesofindia.indiatimes.com/videos/lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f343f6dd465ce0db011a8d7140373af388b27a1b8f78e...</td>\n",
       "      <td>How BK Shivani Found Her Path: A Story of Love...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi8wFBV...</td>\n",
       "      <td>Wed, 02 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>MSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://www.msn.com/en-in/lifestyle/relationsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5a490de6ebe35edfecf027f5183e84438a978e4c8c8e9...</td>\n",
       "      <td>The price of chasing your dreams in China’s me...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi3AFBV...</td>\n",
       "      <td>Wed, 02 Apr 2025 19:08:21 GMT</td>\n",
       "      <td>tudelft.nl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://www.tudelft.nl/en/architecture-and-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e10eaf194d4ef5509ddaeb68383841373341f023ac50a3...</td>\n",
       "      <td>Brooklyn Boy in Gravesend Speeding Crash Loses...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi1wFBV...</td>\n",
       "      <td>Thu, 03 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>bkreader.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://www.bkreader.com/in-other-brooklyn-new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11e5461c064224b3f2562c04e650ec576b443de1d2fac1...</td>\n",
       "      <td>Ranking the top 50 players in the college bask...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiuAFBV...</td>\n",
       "      <td>Wed, 02 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>247Sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://247sports.com/longformarticle/ranking-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0be58923b7be591961973303ae4fd9b5bcd115ad046219...</td>\n",
       "      <td>Burger King Profile: Henry Chang - Burger King...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiZEFVX...</td>\n",
       "      <td>Thu, 03 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>Burger King Newsroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://news.bk.com/blog-posts/bkc-profile-hen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>526865f20fa94e2800a3b627c03e92f41fd0ce8fdf5bee...</td>\n",
       "      <td>Kwibuka 31: How commemoration activities will ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiqAFBV...</td>\n",
       "      <td>Thu, 03 Apr 2025 07:00:00 GMT</td>\n",
       "      <td>The New Times</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\"Bank of New York Mellon\" OR \"BK\") -gossip -c...</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>BK</td>\n",
       "      <td>2026-01-26T16:56:52.059968-05:00</td>\n",
       "      <td>https://www.newtimes.co.rw/article/25377/news/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  d0628ebdbee231311b2356627bc476f92190cfa22bae7d...   \n",
       "1  67e756c3478f59ad1ce1a58e5dd84d20b443ebbf5f58ac...   \n",
       "2  9698e4b440d2804dacb73299a644a2f24e2efd5f5c094b...   \n",
       "3  4f343f6dd465ce0db011a8d7140373af388b27a1b8f78e...   \n",
       "4  d5a490de6ebe35edfecf027f5183e84438a978e4c8c8e9...   \n",
       "5  e10eaf194d4ef5509ddaeb68383841373341f023ac50a3...   \n",
       "6  11e5461c064224b3f2562c04e650ec576b443de1d2fac1...   \n",
       "7  0be58923b7be591961973303ae4fd9b5bcd115ad046219...   \n",
       "8  526865f20fa94e2800a3b627c03e92f41fd0ce8fdf5bee...   \n",
       "\n",
       "                                               title  \\\n",
       "0  BNY launches new blockchain accounting tool wi...   \n",
       "1  “A classical guitar for the modern era”: Harle...   \n",
       "2  How BK Shivani Found Her Path: A Story of Love...   \n",
       "3  How BK Shivani Found Her Path: A Story of Love...   \n",
       "4  The price of chasing your dreams in China’s me...   \n",
       "5  Brooklyn Boy in Gravesend Speeding Crash Loses...   \n",
       "6  Ranking the top 50 players in the college bask...   \n",
       "7  Burger King Profile: Henry Chang - Burger King...   \n",
       "8  Kwibuka 31: How commemoration activities will ...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://news.google.com/rss/articles/CBMipgFBV...   \n",
       "1  https://news.google.com/rss/articles/CBMihgFBV...   \n",
       "2  https://news.google.com/rss/articles/CBMi7AFBV...   \n",
       "3  https://news.google.com/rss/articles/CBMi8wFBV...   \n",
       "4  https://news.google.com/rss/articles/CBMi3AFBV...   \n",
       "5  https://news.google.com/rss/articles/CBMi1wFBV...   \n",
       "6  https://news.google.com/rss/articles/CBMiuAFBV...   \n",
       "7  https://news.google.com/rss/articles/CBMiZEFVX...   \n",
       "8  https://news.google.com/rss/articles/CBMiqAFBV...   \n",
       "\n",
       "                       published                source  summary  \\\n",
       "0  Thu, 03 Apr 2025 07:00:00 GMT               Fortune      NaN   \n",
       "1  Thu, 03 Apr 2025 07:00:00 GMT            MusicRadar      NaN   \n",
       "2  Wed, 02 Apr 2025 07:00:00 GMT        Times of India      NaN   \n",
       "3  Wed, 02 Apr 2025 07:00:00 GMT                   MSN      NaN   \n",
       "4  Wed, 02 Apr 2025 19:08:21 GMT            tudelft.nl      NaN   \n",
       "5  Thu, 03 Apr 2025 07:00:00 GMT          bkreader.com      NaN   \n",
       "6  Wed, 02 Apr 2025 07:00:00 GMT             247Sports      NaN   \n",
       "7  Thu, 03 Apr 2025 07:00:00 GMT  Burger King Newsroom      NaN   \n",
       "8  Thu, 03 Apr 2025 07:00:00 GMT         The New Times      NaN   \n",
       "\n",
       "                                               query target_date ticker  \\\n",
       "0  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "1  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "2  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "3  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "4  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "5  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "6  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "7  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "8  (\"Bank of New York Mellon\" OR \"BK\") -gossip -c...  2025-04-02     BK   \n",
       "\n",
       "                         fetched_at  \\\n",
       "0  2026-01-26T16:56:52.059968-05:00   \n",
       "1  2026-01-26T16:56:52.059968-05:00   \n",
       "2  2026-01-26T16:56:52.059968-05:00   \n",
       "3  2026-01-26T16:56:52.059968-05:00   \n",
       "4  2026-01-26T16:56:52.059968-05:00   \n",
       "5  2026-01-26T16:56:52.059968-05:00   \n",
       "6  2026-01-26T16:56:52.059968-05:00   \n",
       "7  2026-01-26T16:56:52.059968-05:00   \n",
       "8  2026-01-26T16:56:52.059968-05:00   \n",
       "\n",
       "                                         actual_link  \n",
       "0  https://fortune.com/crypto/2025/04/03/bank-new...  \n",
       "1  https://www.musicradar.com/guitars/harley-bent...  \n",
       "2  https://timesofindia.indiatimes.com/videos/lif...  \n",
       "3  https://www.msn.com/en-in/lifestyle/relationsh...  \n",
       "4  https://www.tudelft.nl/en/architecture-and-the...  \n",
       "5  https://www.bkreader.com/in-other-brooklyn-new...  \n",
       "6  https://247sports.com/longformarticle/ranking-...  \n",
       "7  https://news.bk.com/blog-posts/bkc-profile-hen...  \n",
       "8  https://www.newtimes.co.rw/article/25377/news/...  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0bffe12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/gnews_w_links/2024-03-11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cbdd8d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461, 12)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "11144cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/22/2026 03:49:36 PM - not a 200 response: 401 for URL https://www.wsj.com/business/airlines/behind-the-alaska-blowout-a-manufacturing-habit-boeing-cant-break-c05a2ba5?gaa_at=eafs&gaa_n=AWEtsqezmLx-OCnaGNH3KPYnAL2WV3yevqQiQOH2C_3U7CEzQNhl6MxLS9QW&gaa_ts=696eb18a&gaa_sig=4JT3bl5Af_P6FLjDFEQM3OSoOU0rFkyPezCuZVPj1j4gzJ7nAGKcFCZapf6K8hMdpX0HWM3sD14mOYNgoPDB1g%3D%3D\n",
      "01/22/2026 03:49:36 PM - not a 200 response: 401 for URL https://www.wsj.com/business/airlines/southwest-airlines-is-reevaluating-2024-guidance-due-to-boeing-challenges-c0d27c62?gaa_at=eafs&gaa_n=AWEtsqfwdJ5SeLSvxvzMKeLmobgFsgPcnIuVw1nXAy3FG_DoaknCTW2k37nv&gaa_ts=696eb18a&gaa_sig=UEGHFQWeNINd8D-R0BnjFlpncel92UDzeosCVyko8yNLoK3sc2LYwXziVCCTiRthZRpvtuPKH1Eft_vO6JCVYw%3D%3D\n",
      "01/22/2026 03:49:43 PM - not a 200 response: 401 for URL https://www.marketwatch.com/story/reddit-launches-ipo-at-a-valuation-of-up-to-5-5-billion-e062fed1?gaa_at=eafs&gaa_n=AWEtsqcCyjpkyRsnZJicecX9qPe0tzJHWbikqD3OyRw2uHAo5Z88dByzeX8W&gaa_ts=696eb18a&gaa_sig=VjkKYicenYSbnbifOhZeM2OE3lJrdss77BfZytZpL2IsfSedfcsP3gmzW-TRB8a9gGxb8QkNYWAyd_yWYhOsLw%3D%3D\n",
      "01/22/2026 03:49:43 PM - not a 200 response: 401 for URL https://www.barrons.com/articles/apple-stock-price-ai-iphone-f59af9d0?gaa_at=eafs&gaa_n=AWEtsqeL6TcGZGd8Ot7Fv7kJRaMOksnZ_BPXyFfJ8nNwjbKiyV-CxYuoDHYW&gaa_ts=696eb18b&gaa_sig=jKtT5XMP5KaA3XRzmooK_vjgoxRBtVVjMLCEyU76TkfBQvnl7WRIQ0yqIFFZa_TbOljPzXnyAiJXHelHQjytfg%3D%3D\n",
      "01/22/2026 03:49:43 PM - not a 200 response: 401 for URL https://www.barrons.com/articles/apple-car-stock-price-bcb161df?gaa_at=eafs&gaa_n=AWEtsqd2Ya9G9KGCFHGIl5DAtZGaSnrHwN25BlpP3N3j7G_zzXnzrmsf9BN7&gaa_ts=696eb18b&gaa_sig=W6sSTTHOxOO7eh2Q16VicjMJXSgCsSp8aJPo8pqa3pePTYWB4sSKAZixsU0563k4p1qN7XJDR1kIN9sft0xAYQ%3D%3D\n",
      "01/22/2026 03:49:43 PM - not a 200 response: 401 for URL https://www.wsj.com/tech/apple-tweaks-app-store-plans-in-europe-e28ea3e2?gaa_at=eafs&gaa_n=AWEtsqdVctTC13FLS4hwsXQBAf6f2Hdo5cJOLs5rmOEmoeE_U0rd_AeCCmRx&gaa_ts=696eb18b&gaa_sig=kzlSqQuSYHr2kiHwvApxmBkd_dVu3TSLhO6cWdIbXVSym4TUIWqCAV5bIY9T3bgRIeIkNJSgfqrHc7XN_J9haA%3D%3D\n",
      "01/22/2026 03:49:44 PM - not a 200 response: 401 for URL https://www.wsj.com/livecoverage/stock-market-today-dow-jones-03-11-2024/card/tyson-foods-to-close-iowa-plant-as-meatpackers-contend-with-pork-glut-dadlgh3Jix9kLB9zKmuM?gaa_at=eafs&gaa_n=AWEtsqcu2kgElTLMJeBZ4ki1iHhpaedRIn_ma-99tV0V9nKOK0Luq5UsZESL&gaa_ts=696eb18d&gaa_sig=9_zJHZTp874rEiSzr50yGrXl15r-1o8Z-hSqRNPkvAw1ChJGiPXBacA4dFlcaEKtkHgxma8eyVgScVe3Kd2GWw%3D%3D\n",
      "01/22/2026 03:49:44 PM - not a 200 response: 401 for URL https://www.barrons.com/articles/nycb-stock-price-forecast-9ce425fc?gaa_at=eafs&gaa_n=AWEtsqcLLi2vBHm0QOau8RJK71GiYfjRxME9qOUkVkqTcOWzQddyidbggnwE&gaa_ts=696eb18e&gaa_sig=VFmRxNE7EY16NbOw6Db8DiPpmUy4K2dXgXoa2PzXkUpTf5X5CbVOpMkVtdKyN9fu49_NxdNkHdnr1U140OUExA%3D%3D\n",
      "01/22/2026 03:49:44 PM - not a 200 response: 401 for URL https://www.marketwatch.com/story/nycbs-new-chief-executive-making-1-25-million-base-salary-bd8af7b3?gaa_at=eafs&gaa_n=AWEtsqcdtCkDiNsO5fXfDzWOA7BSi6EX4RcI3xBGuA8RW5Vt9nrX8GhyRG7L&gaa_ts=696eb18e&gaa_sig=py1qtUHHtBDDtiZ3naWt6QZPdU9GVsg5OloJA5lPlUXXK3ZKi2MUJmmJPkuIsaUAy1bx3rLLo8FUosRV27dvSg%3D%3D\n",
      "01/22/2026 03:49:44 PM - not a 200 response: 401 for URL https://www.wsj.com/business/autos/having-overtaken-tesla-byd-is-running-into-problems-overseas-7d883f02?gaa_at=eafs&gaa_n=AWEtsqeShCAJqvES3is1t5x1WCQookLXXqSKAlGPUKWczzsp9L3aMn-oY5fW&gaa_ts=696eb18f&gaa_sig=e5kHtHS7AsoJmE20mr-9gtPd3pDPTDYbeg3jvV3l1stMrT7Pz4o-cB7WhJwnhKPTaemHinSirNZRu3HrHhsJeQ%3D%3D\n",
      "01/22/2026 03:49:44 PM - not a 200 response: 401 for URL https://www.wsj.com/business/autos/tesla-ford-receive-poor-grades-in-study-of-driver-assist-technology-adab59e0?gaa_at=eafs&gaa_n=AWEtsqeMFKhjFL_gi_DKFlOZGGVG1XjlAJuW9Xbg8_6YwJuMqMLnc4sIfzgb&gaa_ts=696eb18f&gaa_sig=4lPxXVbGkTvzSgrMVf3SINH5YSkXF1cpaMkTn6-U_47-HOUMbhY6MMIHPTpa4F5lxUyo9ZUEo7arJvmnJlKGgQ%3D%3D\n",
      "01/22/2026 03:49:44 PM - not a 200 response: 401 for URL https://www.marketwatch.com/story/teslas-stock-chart-sends-warning-to-bears-that-momentum-may-have-bottomed-2dfc9cff?gaa_at=eafs&gaa_n=AWEtsqcRD_mWu8CM2xnSQvVsMo_7r0dNeeWkFhS7MTVSodMaysDdeG-jm_82&gaa_ts=696eb18f&gaa_sig=n28w_KWoLS-tayYX3hCuG43f38NyeUkIBRmBykkECJFd16Y2qwU2Jpy7urlXd1u1cNQrJfRMHwhQ5ZuiEb37rw%3D%3D\n",
      "01/22/2026 03:49:52 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:49:52 PM - empty HTML tree: None\n",
      "01/22/2026 03:49:52 PM - not a 200 response: 403 for URL https://www.nytimes.com/2024/03/12/business/john-barnett-boeing-whistleblower-dead.html\n",
      "01/22/2026 03:49:53 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-11/boeing-shares-extend-2024-drop-past-25-on-us-investigation\n",
      "01/22/2026 03:49:57 PM - not a 200 response: 401 for URL https://www.wsj.com/business/airlines/behind-the-alaska-blowout-a-manufacturing-habit-boeing-cant-break-c05a2ba5?gaa_at=eafs&gaa_n=AWEtsqd6PR-PId5S7mtvh-iAxsbYSM7di0Pbc8XJ4dJfsoi8vrUIOQvCryNp&gaa_ts=696eb4a9&gaa_sig=HcOTRm9UgdlPWfORb8lBFmhB9MG_vySUuQL3j1nX3NZhW31k8fnrF6hyy8-oWMhbrG7I9yUOSLOZj1ou05pKHA%3D%3D\n",
      "01/22/2026 03:49:59 PM - not a 200 response: 401 for URL https://www.reuters.com/world/asia-pacific/24-injured-after-technical-problem-latam-sydney-auckland-flight-nz-herald-2024-03-11/\n",
      "01/22/2026 03:50:00 PM - not a 200 response: 403 for URL https://www.nytimes.com/2024/03/11/us/politics/faa-audit-boeing-737-max.html\n",
      "01/22/2026 03:50:02 PM - not a 200 response: 401 for URL https://www.reuters.com/world/us/boeing-whistleblower-found-dead-apparent-suicide-2024-03-12/\n",
      "01/22/2026 03:50:10 PM - not a 200 response: 403 for URL https://www.nytimes.com/2024/03/09/business/boeing-criminal-inquiry-alaska-airlines-flight.html\n",
      "01/22/2026 03:50:11 PM - not a 200 response: 401 for URL https://www.reuters.com/business/aerospace-defense/faa-audit-boeings-737-max-production-found-dozens-issues-nyt-reports-2024-03-12/\n",
      "01/22/2026 03:50:11 PM - not a 200 response: 401 for URL https://www.wsj.com/business/airlines/southwest-airlines-is-reevaluating-2024-guidance-due-to-boeing-challenges-c0d27c62?gaa_at=eafs&gaa_n=AWEtsqepi9GOiPpvijAn-hd4FCJuqqbevo-irEY9q099GP8aH-a1rbWTlS3S&gaa_ts=696eb4a9&gaa_sig=P6UhrwF64pt8_b_VlHW06YriH-1ypHFLg1cdbXLo4KymX02wCFc7rtXwxmK_GQv4ijWIIZ9wMA-3PCJSh9wA4A%3D%3D\n",
      "01/22/2026 03:50:11 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-12/boeing-crisis-blows-up-airlines-growth-plans-as-output-stalls\n",
      "01/22/2026 03:50:13 PM - pycurl error: https://www.thestate.com/news/state/south-carolina/article286575560.html (92, 'HTTP/2 stream 1 was not closed cleanly: INTERNAL_ERROR (err 2)')\n",
      "01/22/2026 03:50:13 PM - not a 200 response: 403 for URL https://washingtonstatestandard.com/2024/03/11/at-seattles-boeing-field-a-rare-glimpse-of-americas-troubled-deportation-flights/\n",
      "01/22/2026 03:50:17 PM - not a 200 response: 401 for URL https://www.reuters.com/business/aerospace-defense/boeing-deliveries-slip-february-27-jetliners-2024-03-12/\n",
      "01/22/2026 03:50:27 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-12/boeing-whistleblower-who-raised-concerns-about-safety-standards-found-dead\n",
      "01/22/2026 03:50:28 PM - not a 200 response: 401 for URL https://www.reuters.com/business/aerospace-defense/new-zealand-says-seizing-black-boxes-latam-boeing-787-2024-03-12/\n",
      "01/22/2026 03:50:28 PM - not a 200 response: 403 for URL https://www.axios.com/2024/03/12/faa-audit-boeing-737\n",
      "01/22/2026 03:50:29 PM - not a 200 response: 401 for URL https://www.reuters.com/business/aerospace-defense/boeing-will-add-compliance-checks-equipment-audits-737-factory-memo-says-2024-03-12/\n",
      "01/22/2026 03:50:33 PM - not a 200 response: 403 for URL https://www.marketplace.org/story/2024/03/11/boeing-incident-plane-safety-trust\n",
      "01/22/2026 03:50:42 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-12/boeing-s-calamities-push-stock-to-its-widest-gap-with-airbus-ever\n",
      "01/22/2026 03:50:45 PM - not a 200 response: 403 for URL https://qz.com/boeing-spirit-aerosystems-faa-dish-soap-1851328802\n",
      "01/22/2026 03:50:49 PM - not a 200 response: 401 for URL https://www.reuters.com/business/aerospace-defense/us-justice-department-opens-criminal-investigation-alaska-airlines-blowout-wsj-2024-03-09/\n",
      "01/22/2026 03:50:51 PM - pycurl error: https://www.cbc.ca/news/world/boeing-investigations-buttigieg-1.7140953 (92, 'HTTP/2 stream 1 was not closed cleanly: INTERNAL_ERROR (err 2)')\n",
      "01/22/2026 03:50:51 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-12/southwest-plans-to-cut-2024-capacity-citing-boeing-challenges-lto8zfrx\n",
      "01/22/2026 03:50:52 PM - not a 200 response: 401 for URL https://www.reuters.com/business/aerospace-defense/us-transport-chief-expects-boeing-cooperate-with-doj-ntsb-737-max-probes-2024-03-11/\n",
      "01/22/2026 03:50:53 PM - not a 200 response: 403 for URL https://www.axios.com/2024/03/11/reddit-ipo-valuation\n",
      "01/22/2026 03:50:54 PM - not a 200 response: 401 for URL https://www.reuters.com/markets/deals/reddit-targets-up-64-bln-valuation-much-awaited-us-ipo-2024-03-11/\n",
      "01/22/2026 03:50:55 PM - not a 200 response: 403 for URL https://www.marketplace.org/story/2024/03/11/reddit-plans-to-let-its-users-get-in-on-the-ground-floor-of-its-initial-public-stock-offering\n",
      "01/22/2026 03:50:56 PM - not a 200 response: 403 for URL https://www.fastcompany.com/91054385/reddit-ipo-update-target-stock-price-nyse-listing-date-nears\n",
      "01/22/2026 03:50:57 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-11/reddit-launches-long-awaited-ipo-with-748-million-target\n",
      "01/22/2026 03:50:59 PM - pycurl error: https://www.nasdaq.com/articles/why-the-upcoming-reddit-ipo-may-not-be-like-twitters (92, 'HTTP/2 stream 1 was not closed cleanly: INTERNAL_ERROR (err 2)')\n",
      "01/22/2026 03:51:00 PM - not a 200 response: 401 for URL https://www.marketwatch.com/story/reddit-launches-ipo-at-a-valuation-of-up-to-5-5-billion-e062fed1?gaa_at=eafs&gaa_n=AWEtsqe089AnTH4SU7bqbtmsD2MQwf5OAs7eJqfMhQgn5zW0bocUa8KW6OY1&gaa_ts=696eb4aa&gaa_sig=dYJRlHxKlzXV0Z88dGXDpbg1-lBPsnEOsNOW17SBh6sZAxjJemOghaVJBIRkrvk57WZDcladtMifFNz_ICtsgw%3D%3D\n",
      "01/22/2026 03:51:02 PM - pycurl error: https://www.nasdaq.com/articles/meme-stocks-madness:-3-stocks-fueling-the-reddit-crowd (92, 'HTTP/2 stream 1 was not closed cleanly: INTERNAL_ERROR (err 2)')\n",
      "01/22/2026 03:51:02 PM - not a 200 response: 403 for URL https://qz.com/reddit-ipo-public-valuation-need-to-know-1851325977\n",
      "01/22/2026 03:51:02 PM - not a 200 response: 403 for URL https://qz.com/reddit-ipo-public-valuation-social-media-pinterest-1851324453\n",
      "01/22/2026 03:51:04 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:51:04 PM - empty HTML tree: None\n",
      "01/22/2026 03:51:24 PM - not a 200 response: 403 for URL https://www.employmentlawworldview.com/apple-v-rivos-lessons-for-companies-facing-claims-of-trade-secret-theft-us/\n",
      "01/22/2026 03:51:28 PM - not a 200 response: 401 for URL https://www.barrons.com/articles/apple-stock-price-ai-iphone-f59af9d0?gaa_at=eafs&gaa_n=AWEtsqdkj2lL5qjZXectXyv5lAVSJpGUK1wn8CNFV1gNxvxa8Wfw-a6Ip2VQ&gaa_ts=696eb4aa&gaa_sig=zNYB28Gxg0HafAHdNddhcug4eAjDVHHpVJLraF5zThD0ri2vfm4Rfl9xUr9aPGu97emapwnXHr0IHi0ySbTURw%3D%3D\n",
      "01/22/2026 03:51:31 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:51:31 PM - empty HTML tree: None\n",
      "01/22/2026 03:51:36 PM - not a 200 response: 401 for URL https://www.barrons.com/articles/apple-car-stock-price-bcb161df?gaa_at=eafs&gaa_n=AWEtsqfIwMGeuai88FFr4lQHLDUxGyOnydsgBFsJVjG8uWCfvgVRjE_XNmIm&gaa_ts=696eb4aa&gaa_sig=JFbfHvJTMu1hpm4mKstUEh91tRXuqJhvWN80e5U0sjgRWlXr1yJRTJfKX9ktxgIqxSuKz3BqBaOqs0kOzfrqOA%3D%3D\n",
      "01/22/2026 03:51:41 PM - not a 200 response: 403 for URL https://appleinsider.com/inside/ios-17/tips/how-to-use-the-new-transcripts-feature-in-apple-podcasts\n",
      "01/22/2026 03:51:45 PM - not a 200 response: 403 for URL https://www.fastcompany.com/91052817/an-early-apple-designer-on-what-makes-an-interface-truly-great\n",
      "01/22/2026 03:51:49 PM - not a 200 response: 403 for URL https://qz.com/apple-tv-plus-ad-supported-tier-1851326711\n",
      "01/22/2026 03:51:50 PM - not a 200 response: 401 for URL https://www.wsj.com/tech/apple-tweaks-app-store-plans-in-europe-e28ea3e2?gaa_at=eafs&gaa_n=AWEtsqfLkN4J0v7Hfh5dbTO5JEZzZ98a8FT8CH7Fn0GZCgWvHnnPqugOxBtX&gaa_ts=696eb4aa&gaa_sig=h3qjkBK1RQHUQSD3QNxQ1mqUGREfwaf_TuBVLpVVdoObv8pC2CmQ1j19Q2Ly0TV12oW1UnwYAZ1maLW_Oq1PtA%3D%3D\n",
      "01/22/2026 03:51:54 PM - not a 200 response: 403 for URL https://lbbonline.com/news/apple-captures-every-magic-moment-in-deutsche-telekom-campaign\n",
      "01/22/2026 03:51:57 PM - not a 200 response: 401 for URL https://www.reuters.com/business/healthcare-pharmaceuticals/novo-nordisk-owner-expand-india-this-year-2024-03-12/\n",
      "01/22/2026 03:51:58 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:51:58 PM - empty HTML tree: None\n",
      "01/22/2026 03:51:58 PM - not a 200 response: 403 for URL https://www.contractpharma.com/catalent-acquisition-by-novo-nordisk-evolution-of-the-industry/\n",
      "01/22/2026 03:51:58 PM - not a 200 response: 403 for URL https://qz.com/amycretin-weight-loss-pill-novo-nordisk-ozempic-wegovy-1851321057\n",
      "01/22/2026 03:52:04 PM - not a 200 response: 401 for URL https://www.reuters.com/business/healthcare-pharmaceuticals/fda-approves-novo-nordisks-wegovy-use-reducing-heart-attack-risks-2024-03-08/\n",
      "01/22/2026 03:52:04 PM - parsed tree length: 0, wrong data type or not valid HTML\n",
      "01/22/2026 03:52:04 PM - empty HTML tree: None\n",
      "01/22/2026 03:52:06 PM - not a 200 response: 403 for URL https://qz.com/ozempic-weight-loss-pill-amycretin-novo-nordisk-1851326591\n",
      "01/22/2026 03:52:07 PM - not a 200 response: 403 for URL https://qz.com/amycretin-novo-nordisk-ozempic-wegovy-1851329800\n",
      "01/22/2026 03:52:09 PM - pycurl error: https://www.washingtonpost.com/technology/2024/03/12/trump-musk-truth-social-sale/ (92, 'HTTP/2 stream 1 was not closed cleanly: INTERNAL_ERROR (err 2)')\n",
      "01/22/2026 03:52:13 PM - not a 200 response: 403 for URL https://www.foodbusinessnews.net/articles/25717-tyson-foods-to-close-another-plant\n",
      "01/22/2026 03:52:14 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/videos/2024-03-11/tyson-uses-migrants-to-fill-unpleasant-jobs\n",
      "01/22/2026 03:52:14 PM - not a 200 response: 401 for URL https://www.reuters.com/markets/commodities/tyson-foods-close-iowa-pork-plant-with-1200-workers-2024-03-11/\n",
      "01/22/2026 03:52:18 PM - not a 200 response: 401 for URL https://www.wsj.com/livecoverage/stock-market-today-dow-jones-03-11-2024/card/tyson-foods-to-close-iowa-plant-as-meatpackers-contend-with-pork-glut-dadlgh3Jix9kLB9zKmuM?gaa_at=eafs&gaa_n=AWEtsqf15dbC1vfoYo0QOwdRZhIJSc_nOh7Swnm2Wo_KXhS4Tk350XJhaQFf&gaa_ts=696eb4ac&gaa_sig=HMWUVnKfezWEnjJh5yQ7PIgmFTWR0q390jeUvfLXwQf2DdtYhvH2GcOHPrEfZZ7Da4OmQpiRmPFHO_F0LpEn4w%3D%3D\n",
      "01/22/2026 03:52:22 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-11/tyson-is-hiring-new-york-immigrants-for-jobs-no-one-else-wants\n",
      "01/22/2026 03:52:24 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-11/tyson-foods-shuts-iowa-pork-plant-as-streamlining-continues\n",
      "01/22/2026 03:52:27 PM - not a 200 response: 401 for URL https://www.reuters.com/technology/nvidia-is-sued-by-authors-over-ai-use-copyrighted-works-2024-03-10/\n",
      "01/22/2026 03:52:29 PM - not a 200 response: 403 for URL https://www.courthousenews.com/novelists-claim-tech-company-nvidia-used-pirated-work-to-train-ai-model/\n",
      "01/22/2026 03:52:29 PM - not a 200 response: 403 for URL https://www.fierce-network.com/tech/mavenir-lured-nvidia-investment-it-was-red-hot\n",
      "01/22/2026 03:52:45 PM - not a 200 response: 403 for URL https://qz.com/nvidia-ai-copyright-lawsuit-1851324908\n",
      "01/22/2026 03:52:46 PM - not a 200 response: 403 for URL https://www.bloomberg.com/opinion/articles/2024-03-12/nvda-vs-csco-a-bubble-by-any-other-metric-is-still-a-bubble\n",
      "01/22/2026 03:52:50 PM - not a 200 response: 403 for URL https://www.awn.com/news/nvidia-and-hp-announce-genai-and-data-science-library-integration\n",
      "01/22/2026 03:52:50 PM - not a 200 response: 403 for URL https://seekingalpha.com/article/4677731-amd-vs-nvidia-stock-which-is-the-better-buy\n",
      "01/22/2026 03:52:51 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-11/nvidia-etf-that-delivers-double-gains-sees-record-flows-volume\n",
      "01/22/2026 03:52:53 PM - not a 200 response: 403 for URL https://seekingalpha.com/article/4677402-nvidia-path-forward-weighing-bull-and-bear-cases\n",
      "01/22/2026 03:52:58 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-12/nvidia-leads-semiconductor-stock-rebound-after-two-day-selloff\n",
      "01/22/2026 03:52:59 PM - not a 200 response: 403 for URL https://www.tweaktown.com/news/96785/micron-hbm3e-for-nvidias-beefed-up-h200-ai-gpu-has-shocked-hbm-competitors-like-sk-hynix/index.html\n",
      "01/22/2026 03:53:02 PM - not a 200 response: 403 for URL https://www.extremetech.com/gaming/nvidia-rtx-50-series-flagship-rumored-to-offer-512-bit-memory-bus-28gbs\n",
      "01/22/2026 03:53:02 PM - not a 200 response: 403 for URL https://www.bizjournals.com/sanfrancisco/news/2024/03/11/authors-sue-nvidia-unapproved-copyright-material.html\n",
      "01/22/2026 03:53:02 PM - not a 200 response: 403 for URL https://stockinvest.us/stock-news/nvidia-stock-downgraded-to-holdaccumulate-2024-03-11\n",
      "01/22/2026 03:53:03 PM - not a 200 response: 403 for URL https://videocardz.com/newz/nvidia-geforce-rtx-50-series-reportedly-features-28-gbps-gddr7-memory\n",
      "01/22/2026 03:53:04 PM - not a 200 response: 403 for URL https://www.lightreading.com/ai-machine-learning/orange-cto-now-s-not-the-time-to-invest-in-nvidia-chips-for-ai\n",
      "01/22/2026 03:53:05 PM - not a 200 response: 403 for URL https://www.extremetech.com/gaming/free-mod-allows-resizable-bar-on-nvidia-turing-gpus-if-you-like-to-live\n",
      "01/22/2026 03:53:09 PM - not a 200 response: 403 for URL https://www.huaweicentral.com/huawei-ascend-910b-ai-chip-seems-as-strong-as-nvidia-processor-report/\n",
      "01/22/2026 03:53:11 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:53:11 PM - empty HTML tree: None\n",
      "01/22/2026 03:53:12 PM - not a 200 response: 401 for URL https://www.reuters.com/business/finance/nycb-closes-1-billion-capital-infusion-deal-2024-03-12/\n",
      "01/22/2026 03:53:12 PM - not a 200 response: 403 for URL https://qz.com/new-york-community-bank-explainer-1851317227\n",
      "01/22/2026 03:53:13 PM - not a 200 response: 401 for URL https://www.barrons.com/articles/nycb-stock-price-forecast-9ce425fc?gaa_at=eafs&gaa_n=AWEtsqdvc8_kWHLDCVqo34iKxxat13omptlf-UK41VjNUAip3o5no22MXNik&gaa_ts=696eb4ae&gaa_sig=dG9eRnegSHPOcvwF3ATgkjT-I4qPJeLcC18FmlI8_rIObJdzwi8ZFpvp-JqvcFv19zkNgSrSC9wj27t8UfPdXA%3D%3D\n",
      "01/22/2026 03:53:13 PM - not a 200 response: 401 for URL https://www.marketwatch.com/story/nycbs-new-chief-executive-making-1-25-million-base-salary-bd8af7b3?gaa_at=eafs&gaa_n=AWEtsqf3EWrLy7R-R31LnBIocoupdHezb32g1U_9utBv4oYTJBoZG-6FCc0X&gaa_ts=696eb4ae&gaa_sig=B2ruo_ekqv56csTj7VH9BIzJCQxu_-FEmi4-SnvAi__naJbFX0As6u0xNfgSZ7zkpubIOK-wKZNCzMKlTP6KeQ%3D%3D\n",
      "01/22/2026 03:53:15 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:53:15 PM - empty HTML tree: None\n",
      "01/22/2026 03:53:15 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/articles/2024-03-12/citadel-s-griffin-says-fed-should-go-slow-to-avoid-devastating-course\n",
      "01/22/2026 03:53:16 PM - not a 200 response: 403 for URL https://www.axios.com/local/twin-cities/2024/03/11/chipotle-first-minnesota-location-1999-stadium-village\n",
      "01/22/2026 03:53:17 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:53:17 PM - empty HTML tree: None\n",
      "01/22/2026 03:53:21 PM - not a 200 response: 403 for URL https://www.axios.com/2024/03/11/chipotle-founder-kernel-robots-vegan-new-restaurant\n",
      "01/22/2026 03:53:31 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:53:31 PM - empty HTML tree: None\n",
      "01/22/2026 03:53:33 PM - not a 200 response: 401 for URL https://www.reuters.com/business/autos-transportation/tesla-rivals-get-low-marks-automated-driving-technology-2024-03-12/\n",
      "01/22/2026 03:53:37 PM - not a 200 response: 401 for URL https://www.wsj.com/business/autos/having-overtaken-tesla-byd-is-running-into-problems-overseas-7d883f02?gaa_at=eafs&gaa_n=AWEtsqckGcJ7NpYPNWnHRMwobJK99mF6S2xykBQ3I9WDQ-27qHIpydfcsClf&gaa_ts=696eb4af&gaa_sig=fc_P4ffY8hKf54sst4Uw3aMi2oDuupPz8xiSLplUw5_OB_5YSFOtrMl1YKWNSe7R1vOISfoVMFWOvgXKNby1lw%3D%3D\n",
      "01/22/2026 03:53:42 PM - not a 200 response: 401 for URL https://www.reuters.com/business/autos-transportation/tesla-official-talks-up-southeast-asia-expansion-chinas-byd-pulls-ahead-2024-03-12/\n",
      "01/22/2026 03:53:42 PM - not a 200 response: 401 for URL https://www.wsj.com/business/autos/tesla-ford-receive-poor-grades-in-study-of-driver-assist-technology-adab59e0?gaa_at=eafs&gaa_n=AWEtsqeJlg50gWEzXFlXy1T6G__J8dtb5FBcKQ4pN3hdyAQ0PKPbeuuHj5VQ&gaa_ts=696eb4af&gaa_sig=GhH5qQYR_Lu_qane93zmMDPHyTrNTfgVhYu5jDLQolx6xlF1Hzx1b07-dMISGdoiNuJIrxJz10T1J5jpvJhdsQ%3D%3D\n",
      "01/22/2026 03:53:43 PM - not a 200 response: 401 for URL https://www.reuters.com/business/autos-transportation/next-autopilot-trial-test-teslas-blame-the-driver-defense-2024-03-11/\n",
      "01/22/2026 03:53:45 PM - not a 200 response: 401 for URL https://www.reuters.com/business/autos-transportation/teslas-german-gigafactory-could-be-supplied-again-monday-says-power-firm-2024-03-11/\n",
      "01/22/2026 03:53:48 PM - not a 200 response: 403 for URL https://seekingalpha.com/news/4078545-the-correlation-between-tesla-and-bitcoin-has-broken-down-ms\n",
      "01/22/2026 03:53:48 PM - not a 200 response: 403 for URL https://insideevs.com/news/711999/tesla-hack-phishing-spare-key/\n",
      "01/22/2026 03:53:49 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:53:49 PM - empty HTML tree: None\n",
      "01/22/2026 03:53:49 PM - not a 200 response: 401 for URL https://www.marketwatch.com/story/teslas-stock-chart-sends-warning-to-bears-that-momentum-may-have-bottomed-2dfc9cff?gaa_at=eafs&gaa_n=AWEtsqfm665hpWz1g7nY-lFIaktgFVe_eMAGMwRaGBnNihUdsXWy4wyFZl-e&gaa_ts=696eb4af&gaa_sig=FLSFLGlEIfyWrDy6u1F7ZohFLGIHr9z1fseN3gMVPyLc7ra6Rbldezlx3t7rU3ocs67Mt7w1gF1Te4PCyvyQIw%3D%3D\n",
      "01/22/2026 03:53:49 PM - not a 200 response: 403 for URL https://insideevs.com/features/711884/taycan-turbo-gt-versus-rivals/\n",
      "01/22/2026 03:53:49 PM - not a 200 response: 403 for URL https://www.iflscience.com/nikola-tesla-thought-hed-picked-up-a-signal-from-intelligent-aliens-73345\n",
      "01/22/2026 03:53:53 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/newsletters/2024-03-12/tesla-abandons-an-auto-lobby-over-emissions-rules\n",
      "01/22/2026 03:54:02 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:54:02 PM - empty HTML tree: None\n",
      "01/22/2026 03:54:05 PM - not a 200 response: 403 for URL https://qz.com/tesla-resale-value-depreciation-elon-musk-price-cuts-1851327545\n",
      "01/22/2026 03:54:07 PM - not a 200 response: 401 for URL https://www.reuters.com/business/autos-transportation/tesla-says-it-will-take-some-time-production-german-factory-fully-resume-2024-03-12/\n",
      "01/22/2026 03:54:07 PM - not a 200 response: 403 for URL https://qz.com/tesla-cybertruck-bulletproof-1851325534\n",
      "01/22/2026 03:54:08 PM - not a 200 response: 403 for URL https://247wallst.com/investing/2024/03/12/if-you-invested-1000-in-tesla-10-years-ago-heres-how-much-youd-have-today/\n",
      "01/22/2026 03:54:08 PM - pycurl error: https://www.nasdaq.com/articles/nio-stock-forecast%3A-can-the-tesla-of-china-live-up-to-the-hype (92, 'HTTP/2 stream 1 was not closed cleanly: INTERNAL_ERROR (err 2)')\n",
      "01/22/2026 03:54:08 PM - not a 200 response: 403 for URL https://qz.com/tesla-ev-germany-factory-lights-on-model-y-suv-arson-1851327702\n",
      "01/22/2026 03:54:08 PM - not a 200 response: 403 for URL https://qz.com/iihs-automated-driver-systems-safety-driver-tesla-lexus-1851329174\n",
      "01/22/2026 03:54:09 PM - parsed tree length: 1, wrong data type or not valid HTML\n",
      "01/22/2026 03:54:09 PM - empty HTML tree: None\n",
      "01/22/2026 03:54:09 PM - not a 200 response: 403 for URL https://www.fastcompany.com/91053273/teslas-new-3000-cybertrunk-tent-must-be-a-prank\n",
      "01/22/2026 03:54:10 PM - not a 200 response: 403 for URL https://www.bizjournals.com/southflorida/news/2024/03/11/tesla-proposes-new-showroom-shops-pembroke-gardens.html\n",
      "01/22/2026 03:54:10 PM - not a 200 response: 403 for URL https://www.thestreet.com/automotive/the-tesla-cybertruck-blacklist-is-real-and-has-claimed-a-victim-owner-says-\n",
      "01/22/2026 03:54:11 PM - not a 200 response: 403 for URL https://www.autoblog.com/features/looks-like-tesla-was-serious-with-its-cybertruck-flipping-threats\n",
      "01/22/2026 03:54:12 PM - not a 200 response: 403 for URL https://seekingalpha.com/article/4677540-tsly-very-bad-high-yield-way-to-invest-in-tesla-stock\n"
     ]
    }
   ],
   "source": [
    "import trafilatura\n",
    "import logging\n",
    "logging.getLogger('trafilatura').setLevel(logging.ERROR)\n",
    "\n",
    "def extract_text(url):\n",
    "    if url == None:\n",
    "        return None\n",
    "    try:\n",
    "        downloaded = trafilatura.fetch_url(url)\n",
    "        text = trafilatura.extract(downloaded)\n",
    "        return text if text else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['full_text'] = df['actual_link'].apply(extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "42965a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   None\n",
       "1                                                   None\n",
       "2      What's going on with Boeing planes? Safety con...\n",
       "3      On Tuesday, Boeing will convene the 2024 Aeros...\n",
       "4      Summary\\n- The cockpit in the 747 underwent tw...\n",
       "                             ...                        \n",
       "456    Man Claims Tesla Autopilot Possibly Saved His ...\n",
       "457    Hanoi (VNA) – Expansion into Southeast Asia is...\n",
       "458    Angela Chao, the younger sister of former U.S....\n",
       "459    Here’s a serious question: Since Tesla’s Cyber...\n",
       "460    (�/� X�\\n� �+ Pi��BDwϔ�[8��� ��H��ګ�I����ܕ��q�...\n",
       "Name: full_text, Length: 461, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6c7378e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_API_TOKEN = \"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\"\n",
    "\n",
    "def summarize_text(text):\n",
    "    if text == None or len(text) == 0:\n",
    "        return None\n",
    "    # API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/sshleifer/distilbart-cnn-12-6\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_API_TOKEN}\"}\n",
    "    \n",
    "    non_ascii = sum(1 for c in text if ord(c) > 127)\n",
    "    if non_ascii / len(text) > 0.3:  # More than 30% non-ASCII\n",
    "        return None\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": text})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]['summary_text']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "51ded91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = summarize_text(df.loc[2]['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "78fb3be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a854a7c5b73449984f15dc8048e9a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3ec3cf42e04829b15cc962c34cdfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1c3f571dd14217840614f6083abdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9707bc3af8d2437c9e6260383c81e095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbc4e7101f14510973a444c9d383d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ad3fb066aa4015973fb65f570c7b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = df.loc[2]['full_text']\n",
    "s = summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)\n",
    "# >>> [{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f6d71b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9059f3fa134d7fbaa55cd160791171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5c4619b48d4f32a077adbcb3f34c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af94177c53847c7a2739f6f930bb3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8911ab7f60914257a9f76885af8c76bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60a099c90b94f5eaf7ad55ede61d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6efe65e8444930a268ad361f24a000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae433a2b1de242ca9ecf45271a1573cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Boeing whistleblower John Barnett found dead 62-year-old John Oliver, a longtime Boeing employee who allegedly blew off a Boeing 787-9 Dreamliner in Sydney, Australia, and Auckland, New Zealand on Monday, causing a self-inflicted wound, and a 737-900's engine crashing into a grassy area, resulting in a tire fall off after takeoff in San Francisco on Thursday.\"}]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = df.loc[2]['full_text']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ace49e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c1c02a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=AutoModelForSeq2SeqLM.from_pretrained(\"KedarPanchal/flan-t5-small-summary-finetune\"),\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    ")\n",
    "\n",
    "def summarize_text(text):\n",
    "    if text == None or len(text) == 0:\n",
    "        return None\n",
    "    \n",
    "    non_ascii = sum(1 for c in text if ord(c) > 127)\n",
    "    if non_ascii / len(text) > 0.3:  # More than 30% non-ASCII\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        s = summarizer(text, min_new_tokens=10, do_sample=False)\n",
    "        return s[0]['summary_text']\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1585dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 200, but your input_length is only 137. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\n",
      "Your max_length is set to 200, but your input_length is only 152. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=76)\n",
      "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 200, but your input_length is only 184. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=92)\n",
      "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 200, but your input_length is only 144. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\n",
      "Your max_length is set to 200, but your input_length is only 104. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 200, but your input_length is only 191. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Your max_length is set to 200, but your input_length is only 185. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=92)\n",
      "Your max_length is set to 200, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 200, but your input_length is only 162. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 200, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 200, but your input_length is only 64. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=32)\n",
      "Your max_length is set to 200, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 200, but your input_length is only 107. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=53)\n"
     ]
    }
   ],
   "source": [
    "df['summary'] = df['full_text'].apply(summarize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "42aa4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/gnews_summarized/2024-03-11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cbc1f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_summ = pd.read_csv('data/gnews_summarized/2024-03-11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1fc63552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "91d4e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Google News Entity Scraper\n",
      "======================================================================\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-07...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 10 new articles through query 1.\n",
      "  Found 10 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-08...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 9 new articles through query 1.\n",
      "  Found 9 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-09...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 9 new articles through query 1.\n",
      "  Found 9 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-10...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 16 new articles through query 1.\n",
      "  Found 16 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-11...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 12 new articles through query 1.\n",
      "  Found 12 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-12...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 1 new articles through query 1.\n",
      "  Found 1 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-13...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 8 new articles through query 1.\n",
      "  Found 8 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-14...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 11 new articles through query 1.\n",
      "  Found 11 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-15...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 12 new articles through query 1.\n",
      "  Found 12 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-16...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 10 new articles through query 1.\n",
      "  Found 10 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-17...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 9 new articles through query 1.\n",
      "  Found 9 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-18...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 4 new articles through query 1.\n",
      "  Found 4 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-19...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 1 new articles through query 1.\n",
      "  Found 1 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-20...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 5 new articles through query 1.\n",
      "  Found 5 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-21...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 8 new articles through query 1.\n",
      "  Found 8 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-22...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 9 new articles through query 1.\n",
      "  Found 9 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-23...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 10 new articles through query 1.\n",
      "  Found 10 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-24...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 5 new articles through query 1.\n",
      "  Found 5 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-25...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 2 new articles through query 1.\n",
      "  Found 2 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-26...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 2 new articles through query 1.\n",
      "  Found 2 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-27...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 6 new articles through query 1.\n",
      "  Found 6 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-28...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 10 new articles through query 1.\n",
      "  Found 10 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-29...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 8 new articles through query 1.\n",
      "  Found 8 new articles total.\n",
      "Warning: Could not load seen IDs from data/state/gnews_seen_ids.csv: 'id'\n",
      "\n",
      "Fetching news for 2025-04-30...\n",
      "  Query 1/1: (\"Bank of New York Mellon\" OR \"BNY\") -gossip -celebrity -\"fantasy sports\" -\"game...\n",
      "\t 21 new articles through query 1.\n",
      "  Found 21 new articles total.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google News Entity Scraper\n",
    "Captures news articles for specified entities over configurable date ranges.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urlparse, parse_qsl, urlencode, urlunparse\n",
    "from dateutil import tz\n",
    "import pandas as pd\n",
    "from pygooglenews import GoogleNews\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION - Modify these to change behavior\n",
    "# ============================================================================\n",
    "\n",
    "# Entities to track (ticker symbols and company names)\n",
    "ENTITIES = {\n",
    "    # 'BA': ['Boeing', 'BA'],\n",
    "    # 'RDDT': ['Reddit', 'RDDT'],\n",
    "    # 'AAPL': ['Apple', 'AAPL'],\n",
    "    # 'NVO': ['Novo Nordisk', 'NVO'],\n",
    "    # 'DJT': ['Trump Media', 'DJT', 'Truth Social'],\n",
    "    # 'TSN': ['Tyson Foods', 'TSN'],\n",
    "    # 'NVDA': ['Nvidia', 'NVDA'],\n",
    "    # 'NYCB': ['New York Community Bank', 'NYCB'],\n",
    "    # 'CMG': ['Chipotle', 'CMG'],\n",
    "    # 'TSLA': ['Tesla', 'TSLA']\n",
    "    'BK': ['Bank of New York Mellon', 'BNY']\n",
    "}\n",
    "\n",
    "# Optional: Add News topics/categories to search for each entity\n",
    "NEWS_TOPICS = [\n",
    "    'earnings',\n",
    "    'financial results',\n",
    "    'acquisition',\n",
    "    'merger',\n",
    "    'product launch',\n",
    "    'regulatory',\n",
    "    'lawsuit',\n",
    "    'stock price',\n",
    "    'leadership change',\n",
    "    'strategy',\n",
    "    # Add more topics as needed\n",
    "]\n",
    "\n",
    "# API configuration\n",
    "LANG = \"en\"\n",
    "COUNTRY = \"US\"\n",
    "\n",
    "# Directory configuration\n",
    "BASE_DIR = 'data'\n",
    "STATE_DIR = os.path.join(BASE_DIR, 'state')\n",
    "SEEN_PATH = os.path.join(STATE_DIR, 'gnews_seen_ids.csv')\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def build_entity_queries(entities: dict, topics: list = None) -> list:\n",
    "    \"\"\"\n",
    "    Build search queries for entities.\n",
    "    \n",
    "    Args:\n",
    "        entities: Dict mapping ticker to list of name variants\n",
    "        topics: Optional list of topics to combine with entity names\n",
    "    \n",
    "    Returns:\n",
    "        List of search query strings\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    for ticker, names in entities.items():\n",
    "        # Base entity query (any news about the entity)\n",
    "        name_parts = ' OR '.join(f'\"{name}\"' for name in names)\n",
    "        base_query = f'({name_parts})'\n",
    "        \n",
    "        # Exclude noise\n",
    "        exclusions = ' -gossip -celebrity -\"fantasy sports\" -\"game recap\"'\n",
    "        \n",
    "        if topics:\n",
    "            # Create topic-specific queries\n",
    "            for topic in topics:\n",
    "                query = f'{base_query} AND \"{topic}\"{exclusions}'\n",
    "                queries.append(query)\n",
    "        else:\n",
    "            # Just search for the entity\n",
    "            queries.append(base_query + exclusions)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "\n",
    "def clean_url(url: str) -> str:\n",
    "    \"\"\"Remove common tracking params to get canonical URL.\"\"\"\n",
    "    try:\n",
    "        p = urlparse(url)\n",
    "        if not p.scheme:\n",
    "            return url\n",
    "        # Filter out tracking parameters\n",
    "        q = [(k, v) for k, v in parse_qsl(p.query, keep_blank_values=True)\n",
    "             if not re.match(r'^(utm_|gclid|fbclid|mc_|ref)', k, re.I)]\n",
    "        return urlunparse((p.scheme, p.netloc, p.path, \"\", urlencode(q), \"\"))\n",
    "    except Exception:\n",
    "        return url\n",
    "\n",
    "\n",
    "def make_id(title: str, canonical_link: str) -> str:\n",
    "    \"\"\"Generate unique ID for article based on title and link.\"\"\"\n",
    "    base = f\"{(title or '').strip()}|{(canonical_link or '').strip()}\"\n",
    "    return hashlib.sha256(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def load_seen(path: str) -> set:\n",
    "    \"\"\"Load set of previously seen article IDs.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return set()\n",
    "    try:\n",
    "        return set(pd.read_csv(path)[\"id\"].astype(str).tolist())\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load seen IDs from {path}: {e}\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "def append_seen(path: str, new_ids: list, run_ts: str) -> None:\n",
    "    \"\"\"Append newly seen article IDs to tracking file.\"\"\"\n",
    "    if not new_ids:\n",
    "        return\n",
    "    df = pd.DataFrame({\"id\": new_ids, \"first_seen_at\": run_ts})\n",
    "    header = not os.path.exists(path)\n",
    "    df.to_csv(path, mode=\"a\", header=header, index=False)\n",
    "\n",
    "\n",
    "def write_master(rows: list, master_path: str) -> None:\n",
    "    \"\"\"Append new articles to master CSV.\"\"\"\n",
    "    if not rows:\n",
    "        return\n",
    "    df = pd.DataFrame(rows)\n",
    "    header = not os.path.exists(master_path)\n",
    "    df.to_csv(master_path, mode=\"a\", header=header, index=False)\n",
    "\n",
    "\n",
    "def extract_ticker(query):\n",
    "    match = re.search(r'OR\\s+\"([^\"]+)\"', query)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN SCRAPING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def run_pull_for_date(target_date: datetime, queries: list, entities: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pull news for a specific date.\n",
    "    \n",
    "    Args:\n",
    "        target_date: The date to pull news for\n",
    "        queries: List of search queries\n",
    "        entities: Entity configuration dict\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame of new articles\n",
    "    \"\"\"\n",
    "    gn = GoogleNews(lang=LANG)\n",
    "    seen = load_seen(SEEN_PATH)\n",
    "    run_iso = datetime.now(tz=tz.tzlocal()).isoformat()\n",
    "    \n",
    "    # Set up date range for this specific day\n",
    "    from_date = target_date.strftime('%Y-%m-%d')\n",
    "    to_date = (target_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    raw_rows, master_rows, new_ids = [], [], []\n",
    "    print(f\"\\nFetching news for {from_date}...\")\n",
    "    \n",
    "    for i, q in enumerate(queries, 1):\n",
    "            print(f\"  Query {i}/{len(queries)}: {q[:80]}...\")\n",
    "            \n",
    "            try:\n",
    "                res = gn.search(q, from_=from_date, to_=to_date)\n",
    "                entries = res.get(\"entries\")\n",
    "                raw_rows = []\n",
    "                for e in entries:\n",
    "                    title = e.get(\"title\", \"\")\n",
    "                    link = e.get(\"link\", \"\")\n",
    "                    src = (e.get(\"source\", {}) or {}).get(\"title\", \"\")\n",
    "                    published = e.get(\"published\", \"\")\n",
    "                    canonical = clean_url(link)\n",
    "                    _id = make_id(title, canonical)\n",
    "                    # entity = extract_entity_from_query(q, entities)\n",
    "                    \n",
    "                    row = {\n",
    "                        \"id\": _id,\n",
    "                        \"title\": title,\n",
    "                        \"link\": canonical,\n",
    "                        \"published\": published,\n",
    "                        \"source\": src,\n",
    "                        \"summary\": '',\n",
    "                        \"query\": q,\n",
    "                        \"target_date\": from_date,\n",
    "                        \"ticker\": extract_ticker(q),\n",
    "                        \"fetched_at\": run_iso\n",
    "                    }\n",
    "                    raw_rows.append(row)\n",
    "                \n",
    "                    if _id not in seen:\n",
    "                        master_rows.append(row)\n",
    "                        new_ids.append(_id)\n",
    "                print(f'\\t {len(master_rows)} new articles through query {i}.')\n",
    "            except Exception as e:\n",
    "                print(f\"    Error with query: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Update seen IDs\n",
    "    append_seen(SEEN_PATH, new_ids, run_iso)\n",
    "    \n",
    "    # Return new articles\n",
    "    print(f\"  Found {len(master_rows)} new articles total.\")\n",
    "    gnews_path = os.path.join(BASE_DIR, \n",
    "                              f'gnews/{target_date.strftime('%Y-%m-%d')}.csv')\n",
    "\n",
    "    write_master(master_rows, gnews_path)\n",
    "    return pd.DataFrame(master_rows)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Google News Entity Scraper\")\n",
    "    print(\"=\" * 70)\n",
    "    # # Date range configuration\n",
    "    for i in range(7,31):\n",
    "        START_DATE = datetime(2025, 4, i) # to 4/10\n",
    "\n",
    "        queries = build_entity_queries(ENTITIES, topics=None)\n",
    "        df = run_pull_for_date(START_DATE, queries, ENTITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "42f4af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/26/2026 05:16:10 PM - not a 200 response: 403 for URL https://www.bizjournals.com/pittsburgh/news/2025/04/07/bny-digital-assets-blockchain-blackrock.html\n",
      "01/26/2026 05:16:15 PM - not a 200 response: 403 for URL https://www.bloomberg.com/news/newsletters/2025-04-07/global-rout-carries-whiff-of-panic-as-trump-holds-fast-on-tariffs\n",
      "01/26/2026 05:16:17 PM - pycurl error: https://www.luxtimes.lu/businessandfinance/spain-s-cecabank-starts-up-in-luxembourg/53481866.html (47, 'Maximum (2) redirects followed')\n",
      "Your max_length is set to 200, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Your max_length is set to 200, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "01/26/2026 05:18:27 PM - not a 200 response: 404 for URL https://www.bny.com/investments/lu/en/institutional/news-and-insights/articles/market-concentration-rarely-lasts.html\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for i in range(7,31):\n",
    "    START_DATE = datetime(2025, 4, i)\n",
    "    df = pd.read_csv(f'data/gnews/{START_DATE.strftime('%Y-%m-%d')}.csv')\n",
    "    df['actual_link'] = df['link'].apply(get_real_url_selenium)\n",
    "    df['full_text'] = df['actual_link'].apply(extract_text)\n",
    "    df['summary'] = df['full_text'].apply(summarize_text)\n",
    "    df.to_csv(f'data/gnews_summarized/{START_DATE.strftime('%Y-%m-%d')}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0f6ef98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "106c6d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5051b7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cd356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51638cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
